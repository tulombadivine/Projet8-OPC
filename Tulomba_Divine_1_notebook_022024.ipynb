{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "441159cc",
      "metadata": {
        "id": "441159cc"
      },
      "source": [
        "# Déployez un modèle dans le cloud\n",
        "\n",
        "\n",
        "# Sommaire :\n",
        "\n",
        "**1. Préambule**<br />\n",
        "&emsp;1.1 Problématique<br />\n",
        "&emsp;1.2 Objectifs dans ce projet<br />\n",
        "&emsp;1.3 Déroulement des étapes du projet<br />\n",
        "**2. Choix techniques généraux retenus**<br />\n",
        "&emsp;2.1 Calcul distribué<br />\n",
        "&emsp;2.2 Transfert Learning<br />\n",
        "**3. Déploiement de la solution en local**<br />\n",
        "&emsp;3.1 Environnement de travail<br />\n",
        "&emsp;3.2 Installation de Spark<br />\n",
        "&emsp;3.3 Installation des packages<br />\n",
        "&emsp;3.4 Import des librairies<br />\n",
        "&emsp;3.5 Définition des PATH pour charger les images et enregistrer les résultats<br />\n",
        "&emsp;3.6 Création de la SparkSession<br />\n",
        "&emsp;3.7 Traitement des données<br />\n",
        "&emsp;&emsp;3.7.1 Chargement des données<br />\n",
        "&emsp;&emsp;3.7.2 Préparation du modèle<br />\n",
        "&emsp;&emsp;3.7.3 Définition du processus de chargement des images et application <br />\n",
        "&emsp;&emsp;&emsp;&emsp;&emsp;de leur featurisation à travers l'utilisation de pandas UDF<br />\n",
        "&emsp;&emsp;3.7.4 Exécution des actions d'extractions de features<br />\n",
        "&emsp;3.8 Chargement des données enregistrées et validation du résultat<br />\n",
        "**4. Déploiement de la solution sur le cloud**<br />\n",
        "&emsp;4.1 Choix du prestataire cloud : AWS<br />\n",
        "&emsp;4.2 Choix de la solution technique : EMR<br />\n",
        "&emsp;4.3 Choix de la solution de stockage des données : Amazon S3<br />\n",
        "&emsp;4.4 Configuration de l'environnement de travail<br />\n",
        "&emsp;4.5 Upload de nos données sur S3<br />\n",
        "&emsp;4.6 Configuration du serveur EMR<br />\n",
        "&emsp;&emsp;4.6.1 Étape 1 : Logiciels et étapes<br />\n",
        "&emsp;&emsp;&emsp;4.6.1.1 Configuration des logiciels<br />\n",
        "&emsp;&emsp;&emsp;4.6.1.2 Modifier les paramètres du logiciel<br />\n",
        "&emsp;&emsp;4.6.2 Étape 2 : Matériel<br />\n",
        "&emsp;&emsp;4.6.3 Étape 3 : Paramètres de cluster généraux<br />\n",
        "&emsp;&emsp;&emsp;4.6.3.1 Options générales<br />\n",
        "&emsp;&emsp;&emsp;4.6.3.2 Actions d'amorçage<br />\n",
        "&emsp;&emsp;4.6.4 Étape 4 : Sécurité<br />\n",
        "&emsp;&emsp;&emsp;4.6.4.1 Options de sécurité<br />\n",
        "&emsp;4.7 Instanciation du serveur<br />\n",
        "&emsp;4.8 Création du tunnel SSH à l'instance EC2 (Maître)<br />\n",
        "&emsp;&emsp;4.8.1 Création des autorisations sur les connexions entrantes<br />\n",
        "&emsp;&emsp;4.8.2 Création du tunnel ssh vers le Driver<br />\n",
        "&emsp;&emsp;4.8.3 Configuration de FoxyProxy<br />\n",
        "&emsp;&emsp;4.8.4 Accès aux applications du serveur EMR via le tunnel ssh<br />\n",
        "&emsp;4.9 Connexion au notebook JupyterHub<br />\n",
        "&emsp;4.10 Exécution du code<br />\n",
        "&emsp;&emsp;4.10.1 Démarrage de la session Spark<br />\n",
        "&emsp;&emsp;4.10.2 Installation des packages<br />\n",
        "&emsp;&emsp;4.10.3 Import des librairies<br />\n",
        "&emsp;&emsp;4.10.4 Définition des PATH pour charger les images et enregistrer les résultats<br />\n",
        "&emsp;&emsp;4.10.5 Traitement des données<br />\n",
        "&emsp;&emsp;&emsp;4.10.5.1 Chargement des données<br />\n",
        "&emsp;&emsp;&emsp;4.10.5.2 Préparation du modèle<br />\n",
        "&emsp;&emsp;&emsp;4.10.5.3 Définition du processus de chargement des images<br />\n",
        "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;et application de leur featurisation à travers l'utilisation de pandas UDF<br />\n",
        "&emsp;&emsp;&emsp;4.10.5.4 Exécutions des actions d'extractions de features<br />\n",
        "&emsp;&emsp;4.10.6 Chargement des données enregistrées et validation du résultat<br />\n",
        "&emsp;4.11 Suivi de l'avancement des tâches avec le Serveur d'Historique Spark<br />\n",
        "&emsp;4.12 Résiliation de l'instance EMR<br />\n",
        "&emsp;4.13 Cloner le serveur EMR (si besoin)<br />\n",
        "&emsp;4.14 Arborescence du serveur S3 à la fin du projet<br />\n",
        "**5. Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec2cee08",
      "metadata": {
        "id": "ec2cee08"
      },
      "source": [
        "# 1. Préambule\n",
        "\n",
        "## 1.1 Problématique\n",
        "\n",
        "La très jeune start-up de l'AgriTech, nommée \"**Fruits**!\", <br />\n",
        "cherche à proposer des solutions innovantes pour la récolte des fruits.\n",
        "\n",
        "La volonté de l’entreprise est de préserver la biodiversité des fruits <br />\n",
        "en permettant des traitements spécifiques pour chaque espèce de fruits <br />\n",
        "en développant des robots cueilleurs intelligents.\n",
        "\n",
        "La start-up souhaite dans un premier temps se faire connaître en mettant <br />\n",
        "à disposition du grand public une application mobile qui permettrait aux <br />\n",
        "utilisateurs de prendre en photo un fruit et d'obtenir des informations sur ce fruit.\n",
        "\n",
        "Pour la start-up, cette application permettrait de sensibiliser le grand public <br />\n",
        "à la biodiversité des fruits et de mettre en place une première version du moteur <br />\n",
        "de classification des images de fruits.\n",
        "\n",
        "De plus, le développement de l’application mobile permettra de construire <br />\n",
        "une première version de l'architecture **Big Data** nécessaire.\n",
        "\n",
        "## 1.2 Objectifs dans ce projet\n",
        "\n",
        "1. Développer une première chaîne de traitement des données qui <br />\n",
        "   comprendra le **preprocessing** et une étape de **réduction de dimension**.\n",
        "2. Tenir compte du fait que <u>le volume de données va augmenter <br />\n",
        "   très rapidement</u> après la livraison de ce projet, ce qui implique de:\n",
        " - Déployer le traitement des données dans un environnement **Big Data**\n",
        " - Développer les scripts en **pyspark** pour effectuer du **calcul distribué**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b95e6ce",
      "metadata": {
        "id": "6b95e6ce"
      },
      "source": [
        "## 1.3 Déroulement des étapes du projet\n",
        "\n",
        "Le projet va être réalisé en 2 temps, dans deux environnements différents. <br />\n",
        "Nous allons dans un premier temps développer et exécuter notre code en local, <br />\n",
        "en travaillant sur un nombre limité d'images à traiter.\n",
        "\n",
        "Une fois les choix techniques validés, nous déploierons notre solution <br />\n",
        "dans un environnement Big Data en mode distribué.\n",
        "\n",
        "<u>Pour cette raison, ce projet sera divisé en 3 parties</u>:\n",
        "1. Liste des choix techniques généraux retenus\n",
        "2. Déploiement de la solution en local\n",
        "3. Déploiement de la solution dans le cloud"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5b34029",
      "metadata": {
        "id": "f5b34029"
      },
      "source": [
        "# 2. Choix techniques généraux retenus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32baf092",
      "metadata": {
        "id": "32baf092"
      },
      "source": [
        "## 2.1 Calcul distribué\n",
        "\n",
        "L’énoncé du projet nous impose de développer des scripts en **pyspark** <br />\n",
        "afin de <u>prendre en compte l’augmentation très rapide du volume <br />\n",
        "de donné après la livraison du projet</u>.\n",
        "\n",
        "Pour comprendre rapidement et simplement ce qu’est **pyspark** <br />\n",
        "et son principe de fonctionnement, nous vous conseillons de lire <br />\n",
        "cet article : [PySpark : Tout savoir sur la librairie Python](https://datascientest.com/pyspark)\n",
        "\n",
        "<u>Le début de l’article nous dit ceci </u>:<br />\n",
        "« *Lorsque l’on parle de traitement de bases de données sur python, <br />\n",
        "on pense immédiatement à la librairie pandas. Cependant, lorsqu’on a <br />\n",
        "affaire à des bases de données trop massives, les calculs deviennent trop lents.<br />\n",
        "Heureusement, il existe une autre librairie python, assez proche <br />\n",
        "de pandas, qui permet de traiter des très grandes quantités de données : PySpark.<br />\n",
        "Apache Spark est un framework open-source développé par l’AMPLab <br />\n",
        "de UC Berkeley permettant de traiter des bases de données massives <br />\n",
        "en utilisant le calcul distribué, technique qui consiste à exploiter <br />\n",
        "plusieurs unités de calcul réparties en clusters au profit d’un seul <br />\n",
        "projet afin de diviser le temps d’exécution d’une requête.<br />\n",
        "Spark a été développé en Scala et est au meilleur de ses capacités <br />\n",
        "dans son langage natif. Cependant, la librairie PySpark propose de <br />\n",
        "l’utiliser avec le langage Python, en gardant des performances <br />\n",
        "similaires à des implémentations en Scala.<br />\n",
        "Pyspark est donc une bonne alternative à la librairie pandas lorsqu’on <br />\n",
        "cherche à traiter des jeux de données trop volumineux qui entraînent <br />\n",
        "des calculs trop chronophages.* »\n",
        "\n",
        "Comme nous le constatons, **pySpark** est un moyen de communiquer <br />\n",
        "avec **Spark** via le langage **Python**.<br />\n",
        "**Spark**, quant à lui, est un outil qui permet de gérer et de coordonner <br />\n",
        "l'exécution de tâches sur des données à travers un groupe d'ordinateurs. <br />\n",
        "<u>Spark (ou Apache Spark) est un framework open source de calcul distribué <br />\n",
        "in-memory pour le traitement et l'analyse de données massives</u>.\n",
        "\n",
        "Un autre [article très intéressant et beaucoup plus complet pour <br />\n",
        "comprendre le **fonctionnement de Spark**](https://www.veonum.com/apache-spark-pour-les-nuls/), ainsi que le rôle <br />\n",
        "des **Spark Session** que nous utiliserons dans ce projet.\n",
        "\n",
        "<u>Voici également un extrait</u>:\n",
        "\n",
        "*Les applications Spark se composent d’un pilote (« driver process ») <br />\n",
        "et de plusieurs exécuteurs (« executor processes »). Il peut être configuré <br />\n",
        "pour être lui-même l’exécuteur (local mode) ou en utiliser autant que <br />\n",
        "nécessaire pour traiter l’application, Spark prenant en charge la mise <br />\n",
        "à l’échelle automatique par une configuration d’un nombre minimum <br />\n",
        "et maximum d’exécuteurs.*\n",
        "\n",
        "![Schéma de Spark](img/spark-schema.png)\n",
        "\n",
        "*Le driver (parfois appelé « Spark Session ») distribue et planifie <br />\n",
        "les tâches entre les différents exécuteurs qui les exécutent et permettent <br />\n",
        "un traitement réparti. Il est le responsable de l’exécution du code <br />\n",
        "sur les différentes machines.\n",
        "\n",
        "Chaque exécuteur est un processus Java Virtual Machine (JVM) distinct <br />\n",
        "dont il est possible de configurer le nombre de CPU et la quantité de <br />\n",
        "mémoire qui lui est alloué. <br />\n",
        "Une seule tâche peut traiter un fractionnement de données à la fois.*\n",
        "\n",
        "Dans les deux environnements (Local et Cloud) nous utiliserons donc **Spark** <br />\n",
        "et nous l’exploiterons à travers des scripts python grâce à **PySpark**.\n",
        "\n",
        "Dans la <u>version locale</u> de notre script nous **simulerons <br />\n",
        "le calcul distribué** afin de valider que notre solution fonctionne.<br />\n",
        "Dans la <u>version cloud</u> nous **réaliserons les opérations sur un cluster de machine**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5364c9f9",
      "metadata": {
        "id": "5364c9f9"
      },
      "source": [
        "## 2.2 Transfert Learning\n",
        "\n",
        "L'énoncé du projet nous demande également de <br />\n",
        "réaliser une première chaîne de traitement <br />\n",
        "des données qui comprendra le preprocessing et <br />\n",
        "une étape de réduction de dimension.\n",
        "\n",
        "Il est également précisé qu'il n'est pas nécessaire <br />\n",
        "d'entraîner un modèle pour le moment.\n",
        "\n",
        "Nous décidons de partir sur une solution de **transfert learning**.\n",
        "\n",
        "Simplement, le **transfert learning** consiste <br />\n",
        "à utiliser la connaissance déjà acquise <br />\n",
        "par un modèle entraîné (ici **MobileNetV2**) pour <br />\n",
        "l'adapter à notre problématique.\n",
        "\n",
        "Nous allons fournir au modèle nos images, et nous allons <br />\n",
        "<u>récupérer l'avant dernière couche</u> du modèle.<br />\n",
        "En effet la dernière couche de modèle est une couche softmax <br />\n",
        "qui permet la classification des images ce que nous ne <br />\n",
        "souhaitons pas dans ce projet.\n",
        "\n",
        "L'avant dernière couche correspond à un **vecteur <br />\n",
        "réduit** de dimension (1,1,1280).\n",
        "\n",
        "Cela permettra de réaliser une première version du moteur <br />\n",
        "pour la classification des images des fruits.\n",
        "\n",
        "**MobileNetV2** a été retenu pour sa <u>rapidité d'exécution</u>, <br />\n",
        "particulièrement adaptée pour le traitement d'un gros volume <br />\n",
        "de données ainsi que la <u>faible dimensionnalité du vecteur <br />\n",
        "de caractéristique en sortie</u> (1,1,1280)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e89a2da",
      "metadata": {
        "id": "1e89a2da"
      },
      "source": [
        "# 3. Déploiement de la solution en local\n",
        "\n",
        "\n",
        "## 3.1 Environnement de travail\n",
        "\n",
        "Pour des raisons de simplicité, nous développons dans un environnement <br />\n",
        "Linux Unbuntu (exécuté depuis une machine Windows dans une machine virtuelle)\n",
        "* Pour installer une machine virtuelle :  https://www.malekal.com/meilleurs-logiciels-de-machine-virtuelle-gratuits-ou-payants/\n",
        "\n",
        "## 3.2 Installation de Spark\n",
        "\n",
        "[La première étape consiste à installer Spark ](https://computingforgeeks.com/how-to-install-apache-spark-on-ubuntu-debian/)\n",
        "\n",
        "## 3.3 Installation des packages\n",
        "\n",
        "<u>On installe ensuite à l'aide de la commande **pip** <br />\n",
        "les packages qui nous seront nécessaires</u> :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Montez votre Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KagnOIJDkgf0",
        "outputId": "fa21fc85-02ae-479d-8bfe-783bf8328d7c"
      },
      "id": "KagnOIJDkgf0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "728d9256",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "728d9256",
        "outputId": "1fdf9d42-36a7-40cc-f1af-482e24b3793e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (10.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from Pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from Pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from Pandas) (1.23.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=b1a5950948d794504652035dfa8d123510efe0a074942e7413d4d40af97d637e\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install Pandas pillow tensorflow pyspark pyarrow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33a43845",
      "metadata": {
        "id": "33a43845"
      },
      "source": [
        "## 3.4 Import des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c0c74f",
      "metadata": {
        "id": "a5c0c74f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras import Model\n",
        "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "661ff67c",
      "metadata": {
        "id": "661ff67c"
      },
      "source": [
        "## 3.5 Définition des PATH pour charger les images <br /> et enregistrer les résultats\n",
        "\n",
        "Dans cette version locale nous partons du principe que les données <br />\n",
        "sont stockées dans le même répertoire que le notebook.<br />\n",
        "Nous n'utilisons qu'un extrait de **300 images** à traiter dans cette <br />\n",
        "première version en local.<br />\n",
        "L'extrait des images à charger est stockée dans le dossier **Test1**.<br />\n",
        "Nous enregistrerons le résultat de notre traitement <br />\n",
        "dans le dossier \"**Results_Local**\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde0aa67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cde0aa67",
        "outputId": "569637b9-2cf9-4420-f4ef-0cbc0da99078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PATH:        /content\n",
            "PATH_Data:   /content/drive/MyDrive/OC-Projet-8/data/Test1\n",
            "PATH_Result: /content/drive/MyDrive/OC-Projet-8/data/Results\n"
          ]
        }
      ],
      "source": [
        "PATH = os.getcwd()\n",
        "PATH_Data = '/content/drive/MyDrive/OC-Projet-8/data/Test1'\n",
        "PATH_Result = '/content/drive/MyDrive/OC-Projet-8/data/Results'\n",
        "print('PATH:        '+\\\n",
        "      PATH+'\\nPATH_Data:   '+\\\n",
        "      PATH_Data+'\\nPATH_Result: '+PATH_Result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da5e637a",
      "metadata": {
        "id": "da5e637a"
      },
      "source": [
        "## 3.6 Création de la SparkSession\n",
        "\n",
        "L’application Spark est contrôlée grâce à un processus de pilotage (driver process) appelé **SparkSession**. <br />\n",
        "<u>Une instance de **SparkSession** est la façon dont Spark exécute les fonctions définies par l’utilisateur <br />\n",
        "dans l’ensemble du cluster</u>. <u>Une SparkSession correspond toujours à une application Spark</u>.\n",
        "\n",
        "<u>Ici nous créons une session spark en spécifiant dans l'ordre</u> :\n",
        " 1. un **nom pour l'application**, qui sera affichée dans l'interface utilisateur Web Spark \"**P8**\"\n",
        " 2. que l'application doit s'exécuter **localement**. <br />\n",
        "   Nous ne définissons pas le nombre de cœurs à utiliser (comme .master('local[4]) pour 4 cœurs à utiliser), <br />\n",
        "   nous utiliserons donc tous les cœurs disponibles dans notre processeur.<br />\n",
        " 3. une option de configuration supplémentaire permettant d'utiliser le **format \"parquet\"** <br />\n",
        "   que nous utiliserons pour enregistrer et charger le résultat de notre travail.\n",
        " 4. vouloir **obtenir une session spark** existante ou si aucune n'existe, en créer une nouvelle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7bea157",
      "metadata": {
        "id": "b7bea157"
      },
      "outputs": [],
      "source": [
        "spark = (SparkSession\n",
        "             .builder\n",
        "             .appName('P8')\n",
        "             .master('local')\n",
        "             .config(\"spark.sql.parquet.writeLegacyFormat\", 'true')\n",
        "             .getOrCreate()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c8b53ac",
      "metadata": {
        "id": "5c8b53ac"
      },
      "source": [
        "<u>Nous créons également la variable \"**sc**\" qui est un **SparkContext** issue de la variable **spark**</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14aeccb1",
      "metadata": {
        "id": "14aeccb1"
      },
      "outputs": [],
      "source": [
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a086010",
      "metadata": {
        "id": "5a086010"
      },
      "source": [
        "<u>Affichage des informations de Spark en cours d'execution</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e97bf13b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "e97bf13b",
        "outputId": "aeaaeeed-c00d-4a88-af80-870eca36d7a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2237968bb0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://deb57cd2e336:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>P8</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "195a88b0",
      "metadata": {
        "id": "195a88b0"
      },
      "source": [
        "## 3.7 Traitement des données\n",
        "\n",
        "<u>Dans la suite de notre flux de travail, <br />\n",
        "nous allons successivement</u> :\n",
        "1. Préparer nos données\n",
        "    1. Importer les images dans un dataframe **pandas UDF**\n",
        "    2. Associer aux images leur **label**\n",
        "    3. Préprocesser en **redimensionnant nos images pour <br />\n",
        "       qu'elles soient compatibles avec notre modèle**\n",
        "2. Préparer notre modèle\n",
        "    1. Importer le modèle **MobileNetV2**\n",
        "    2. Créer un **nouveau modèle** dépourvu de la dernière couche de MobileNetV2\n",
        "3. Définir le processus de chargement des images et l'application <br />\n",
        "   de leur featurisation à travers l'utilisation de pandas UDF\n",
        "3. Exécuter les actions d'extraction de features\n",
        "4. Enregistrer le résultat de nos actions\n",
        "5. Tester le bon fonctionnement en chargeant les données enregistrées\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "386fe0bc",
      "metadata": {
        "id": "386fe0bc"
      },
      "source": [
        "### 3.7.1 Chargement des données\n",
        "\n",
        "Les images sont chargées au format binaire, ce qui offre, <br />\n",
        "plus de souplesse dans la façon de prétraiter les images.\n",
        "\n",
        "Avant de charger les images, nous spécifions que nous voulons charger <br />\n",
        "uniquement les fichiers dont l'extension est **jpg**.\n",
        "\n",
        "Nous indiquons également de charger tous les objets possibles contenus <br />\n",
        "dans les sous-dossiers du dossier communiqué."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e68e53b9",
      "metadata": {
        "id": "e68e53b9"
      },
      "outputs": [],
      "source": [
        "images = spark.read.format(\"binaryFile\") \\\n",
        "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
        "  .option(\"recursiveFileLookup\", \"true\") \\\n",
        "  .load(PATH_Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645faeaf",
      "metadata": {
        "id": "645faeaf"
      },
      "source": [
        "<u>Affichage des 5 premières images contenant</u> :\n",
        " - le path de l'image\n",
        " - la date et heure de sa dernière modification\n",
        " - sa longueur\n",
        " - son contenu encodé en valeur hexadécimal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "863981e5",
      "metadata": {
        "id": "863981e5"
      },
      "source": [
        "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n",
        "    une colonne contenant les **labels** de chaque image</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a08b0494",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a08b0494",
        "outputId": "9003d82e-37d4-4e62-a22e-aa5433083b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- path: string (nullable = true)\n",
            " |-- modificationTime: timestamp (nullable = true)\n",
            " |-- length: long (nullable = true)\n",
            " |-- content: binary (nullable = true)\n",
            " |-- label: string (nullable = true)\n",
            "\n",
            "None\n",
            "+------------------------------------------------------------------------+---------+\n",
            "|path                                                                    |label    |\n",
            "+------------------------------------------------------------------------+---------+\n",
            "|file:/content/drive/MyDrive/OC-Projet-8/data/Test1/Raspberry/206_100.jpg|Raspberry|\n",
            "|file:/content/drive/MyDrive/OC-Projet-8/data/Test1/Raspberry/199_100.jpg|Raspberry|\n",
            "|file:/content/drive/MyDrive/OC-Projet-8/data/Test1/Raspberry/208_100.jpg|Raspberry|\n",
            "|file:/content/drive/MyDrive/OC-Projet-8/data/Test1/Raspberry/205_100.jpg|Raspberry|\n",
            "|file:/content/drive/MyDrive/OC-Projet-8/data/Test1/Raspberry/110_100.jpg|Raspberry|\n",
            "|file:/content/drive/MyDrive/OC-Projet-8/data/Test1/Raspberry/207_100.jpg|Raspberry|\n",
            "|file:/content/drive/MyDrive/OC-Projet-8/data/Test1/Raspberry/203_100.jpg|Raspberry|\n",
            "|file:/content/drive/MyDrive/OC-Projet-8/data/Test1/Raspberry/213_100.jpg|Raspberry|\n",
            "|file:/content/drive/MyDrive/OC-Projet-8/data/Test1/Raspberry/241_100.jpg|Raspberry|\n",
            "|file:/content/drive/MyDrive/OC-Projet-8/data/Test1/Raspberry/242_100.jpg|Raspberry|\n",
            "+------------------------------------------------------------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
        "print(images.printSchema())\n",
        "print(images.select('path','label').show(10,False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d47705",
      "metadata": {
        "id": "83d47705"
      },
      "source": [
        "### 3.7.2 Préparation du modèle\n",
        "\n",
        "Je vais utiliser la technique du **transfert learning** pour extraire les features des images.<br />\n",
        "J'ai choisi d'utiliser le modèle **MobileNetV2** pour sa rapidité d'exécution comparée <br />\n",
        "à d'autres modèles comme *VGG16* par exemple.\n",
        "\n",
        "Pour en savoir plus sur la conception et le fonctionnement de MobileNetV2, <br />\n",
        "je vous invite à lire [cet article](https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c).\n",
        "\n",
        "<u>Voici le schéma de son architecture globale</u> :\n",
        "\n",
        "![Architecture de MobileNetV2](img/mobilenetv2_architecture.png)\n",
        "\n",
        "Il existe une dernière couche qui sert à classer les images <br />\n",
        "selon 1000 catégories que nous ne voulons pas utiliser.<br />\n",
        "L'idée dans ce projet est de récupérer le **vecteur de caractéristiques <br />\n",
        "de dimensions (1,1,1280)** qui servira, plus tard, au travers d'un moteur <br />\n",
        "de classification à reconnaitre les différents fruits du jeu de données.\n",
        "\n",
        "Comme d'autres modèles similaires, **MobileNetV2**, lorsqu'on l'utilise <br />\n",
        "en incluant toutes ses couches, attend obligatoirement des images <br />\n",
        "de dimension (224,224,3). Nos images étant toutes de dimension (100,100,3), <br />\n",
        "nous devrons simplement les **redimensionner** avant de les confier au modèle.\n",
        "\n",
        "<u>Dans l'odre</u> :\n",
        " 1. Nous chargeons le modèle **MobileNetV2** avec les poids **précalculés** <br />\n",
        "    issus d'**imagenet** et en spécifiant le format de nos images en entrée\n",
        " 2. Nous créons un nouveau modèle avec:\n",
        "  - <u>en entrée</u> : l'entrée du modèle MobileNetV2\n",
        "  - <u>en sortie</u> : l'avant dernière couche du modèle MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cdd9bdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cdd9bdf",
        "outputId": "1c5b0748-7abd-4279-8d24-1802c6c73e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14536120/14536120 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model = MobileNetV2(weights='imagenet',\n",
        "                    include_top=True,\n",
        "                    input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d6b68d",
      "metadata": {
        "id": "99d6b68d"
      },
      "outputs": [],
      "source": [
        "new_model = Model(inputs=model.input,\n",
        "                  outputs=model.layers[-2].output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b197379",
      "metadata": {
        "id": "7b197379"
      },
      "source": [
        "Affichage du résumé de notre nouveau modèle où nous constatons <br />\n",
        "que <u>nous récupérons bien en sortie un vecteur de dimension (1, 1, 1280)</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8207725",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8207725",
        "outputId": "4b40e232-fd1a-4b98-a9a8-27b003e211a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)              (None, 112, 112, 32)         864       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalizati  (None, 112, 112, 32)         128       ['Conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)           (None, 112, 112, 32)         0         ['bn_Conv1[0][0]']            \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (D  (None, 112, 112, 32)         288       ['Conv1_relu[0][0]']          \n",
            " epthwiseConv2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN  (None, 112, 112, 32)         128       ['expanded_conv_depthwise[0][0\n",
            "  (BatchNormalization)                                              ]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_re  (None, 112, 112, 32)         0         ['expanded_conv_depthwise_BN[0\n",
            " lu (ReLU)                                                          ][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_project (Con  (None, 112, 112, 16)         512       ['expanded_conv_depthwise_relu\n",
            " v2D)                                                               [0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (  (None, 112, 112, 16)         64        ['expanded_conv_project[0][0]'\n",
            " BatchNormalization)                                                ]                             \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)     (None, 112, 112, 96)         1536      ['expanded_conv_project_BN[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNo  (None, 112, 112, 96)         384       ['block_1_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)  (None, 112, 112, 96)         0         ['block_1_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D  (None, 113, 113, 96)         0         ['block_1_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_1_depthwise (Depthwi  (None, 56, 56, 96)           864       ['block_1_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (Batc  (None, 56, 56, 96)           384       ['block_1_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (Re  (None, 56, 56, 96)           0         ['block_1_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)    (None, 56, 56, 24)           2304      ['block_1_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_1_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_1_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_2_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_2_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_depthwise (Depthwi  (None, 56, 56, 144)          1296      ['block_2_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (Batc  (None, 56, 56, 144)          576       ['block_2_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (Re  (None, 56, 56, 144)          0         ['block_2_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)    (None, 56, 56, 24)           3456      ['block_2_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_2_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_add (Add)           (None, 56, 56, 24)           0         ['block_1_project_BN[0][0]',  \n",
            "                                                                     'block_2_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_2_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_3_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_3_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D  (None, 57, 57, 144)          0         ['block_3_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_3_depthwise (Depthwi  (None, 28, 28, 144)          1296      ['block_3_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (Batc  (None, 28, 28, 144)          576       ['block_3_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (Re  (None, 28, 28, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)    (None, 28, 28, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_3_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_3_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_4_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_4_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_4_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_4_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_add (Add)           (None, 28, 28, 32)           0         ['block_3_project_BN[0][0]',  \n",
            "                                                                     'block_4_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_4_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_5_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_5_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_5_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_5_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_5_add (Add)           (None, 28, 28, 32)           0         ['block_4_add[0][0]',         \n",
            "                                                                     'block_5_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_5_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_6_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_6_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D  (None, 29, 29, 192)          0         ['block_6_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_6_depthwise (Depthwi  (None, 14, 14, 192)          1728      ['block_6_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (Batc  (None, 14, 14, 192)          768       ['block_6_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (Re  (None, 14, 14, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)    (None, 14, 14, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_6_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_6_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_7_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_7_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_7_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_7_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_add (Add)           (None, 14, 14, 64)           0         ['block_6_project_BN[0][0]',  \n",
            "                                                                     'block_7_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_7_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_8_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_8_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_8_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_8_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_8_add (Add)           (None, 14, 14, 64)           0         ['block_7_add[0][0]',         \n",
            "                                                                     'block_8_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_8_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_9_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_9_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_9_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_9_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_9_add (Add)           (None, 14, 14, 64)           0         ['block_8_add[0][0]',         \n",
            "                                                                     'block_9_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)    (None, 14, 14, 384)          24576     ['block_9_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchN  (None, 14, 14, 384)          1536      ['block_10_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU  (None, 14, 14, 384)          0         ['block_10_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_10_depthwise (Depthw  (None, 14, 14, 384)          3456      ['block_10_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (Bat  (None, 14, 14, 384)          1536      ['block_10_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (R  (None, 14, 14, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)   (None, 14, 14, 96)           36864     ['block_10_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_10_project_BN (Batch  (None, 14, 14, 96)           384       ['block_10_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_10_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_11_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_11_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_11_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_11_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_11_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_11_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_11_project_BN (Batch  (None, 14, 14, 96)           384       ['block_11_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_add (Add)          (None, 14, 14, 96)           0         ['block_10_project_BN[0][0]', \n",
            "                                                                     'block_11_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_11_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_12_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_12_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_12_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_12_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_12_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_12_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_12_project_BN (Batch  (None, 14, 14, 96)           384       ['block_12_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_12_add (Add)          (None, 14, 14, 96)           0         ['block_11_add[0][0]',        \n",
            "                                                                     'block_12_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_12_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_13_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_13_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2  (None, 15, 15, 576)          0         ['block_13_expand_relu[0][0]']\n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block_13_depthwise (Depthw  (None, 7, 7, 576)            5184      ['block_13_pad[0][0]']        \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (Bat  (None, 7, 7, 576)            2304      ['block_13_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (R  (None, 7, 7, 576)            0         ['block_13_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)   (None, 7, 7, 160)            92160     ['block_13_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_13_project_BN (Batch  (None, 7, 7, 160)            640       ['block_13_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_13_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_14_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_14_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_14_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_14_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_14_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_14_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_14_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_14_project_BN (Batch  (None, 7, 7, 160)            640       ['block_14_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_add (Add)          (None, 7, 7, 160)            0         ['block_13_project_BN[0][0]', \n",
            "                                                                     'block_14_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_14_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_15_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_15_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_15_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_15_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_15_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_15_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_15_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_15_project_BN (Batch  (None, 7, 7, 160)            640       ['block_15_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_15_add (Add)          (None, 7, 7, 160)            0         ['block_14_add[0][0]',        \n",
            "                                                                     'block_15_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_15_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_16_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_16_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_16_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_16_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_16_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_16_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)   (None, 7, 7, 320)            307200    ['block_16_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_16_project_BN (Batch  (None, 7, 7, 320)            1280      ['block_16_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)             (None, 7, 7, 1280)           409600    ['block_16_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalizat  (None, 7, 7, 1280)           5120      ['Conv_1[0][0]']              \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " out_relu (ReLU)             (None, 7, 7, 1280)           0         ['Conv_1_bn[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 1280)                 0         ['out_relu[0][0]']            \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2257984 (8.61 MB)\n",
            "Trainable params: 2223872 (8.48 MB)\n",
            "Non-trainable params: 34112 (133.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a0adcf5",
      "metadata": {
        "id": "2a0adcf5"
      },
      "source": [
        "Tous les workeurs doivent pouvoir accéder au modèle ainsi qu'à ses poids. <br />\n",
        "Une bonne pratique consiste à charger le modèle sur le driver puis à diffuser <br />\n",
        "ensuite les poids aux différents workeurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc53ff0",
      "metadata": {
        "id": "1cc53ff0"
      },
      "outputs": [],
      "source": [
        "brodcast_weights = sc.broadcast(new_model.get_weights())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc0e34e",
      "metadata": {
        "id": "8bc0e34e"
      },
      "source": [
        "<u>Mettons cela sous forme de fonction</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd51ba9",
      "metadata": {
        "id": "3fd51ba9"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "    \"\"\"\n",
        "    Returns a MobileNetV2 model with top layer removed\n",
        "    and broadcasted pretrained weights.\n",
        "    \"\"\"\n",
        "    model = MobileNetV2(weights='imagenet',\n",
        "                        include_top=True,\n",
        "                        input_shape=(224, 224, 3))\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    new_model = Model(inputs=model.input,\n",
        "                  outputs=model.layers[-2].output)\n",
        "    new_model.set_weights(brodcast_weights.value)\n",
        "    return new_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5620876",
      "metadata": {
        "id": "e5620876"
      },
      "source": [
        "### 3.7.3 Définition du processus de chargement des images et application <br/>de leur featurisation à travers l'utilisation de pandas UDF\n",
        "\n",
        "Ce notebook définit la logique par étapes, jusqu'à Pandas UDF.\n",
        "\n",
        "<u>L'empilement des appels est la suivante</u> :\n",
        "\n",
        "- Pandas UDF\n",
        "  - featuriser une série d'images pd.Series\n",
        "   - prétraiter une image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc4e5f69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc4e5f69",
        "outputId": "6604d770-d046-4ea3-ba64-ca6bcf6a2247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def preprocess(content):\n",
        "    \"\"\"\n",
        "    Preprocesses raw image bytes for prediction.\n",
        "    \"\"\"\n",
        "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
        "    arr = img_to_array(img)\n",
        "    return preprocess_input(arr)\n",
        "\n",
        "def featurize_series(model, content_series):\n",
        "    \"\"\"\n",
        "    Featurize a pd.Series of raw images using the input model.\n",
        "    :return: a pd.Series of image features\n",
        "    \"\"\"\n",
        "    input = np.stack(content_series.map(preprocess))\n",
        "    preds = model.predict(input)\n",
        "    # For some layers, output features will be multi-dimensional tensors.\n",
        "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
        "    output = [p.flatten() for p in preds]\n",
        "    return pd.Series(output)\n",
        "\n",
        "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
        "def featurize_udf(content_series_iter):\n",
        "    '''\n",
        "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
        "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
        "\n",
        "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
        "                              is a pandas Series of image data.\n",
        "    '''\n",
        "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
        "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
        "    model = model_fn()\n",
        "    for content_series in content_series_iter:\n",
        "        yield featurize_series(model, content_series)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bdf2ef9",
      "metadata": {
        "id": "2bdf2ef9"
      },
      "source": [
        "### 3.7.4 Exécution des actions d'extraction de features\n",
        "\n",
        "Les Pandas UDF, sur de grands enregistrements (par exemple, de très grandes images), <br />\n",
        "peuvent rencontrer des erreurs de type Out Of Memory (OOM).<br />\n",
        "Si vous rencontrez de telles erreurs dans la cellule ci-dessous, <br />\n",
        "essayez de réduire la taille du lot Arrow via 'maxRecordsPerBatch'\n",
        "\n",
        "Je n'utiliserai pas cette commande dans ce projet <br />\n",
        "et je laisse donc la commande en commentaire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f30d28c",
      "metadata": {
        "id": "1f30d28c"
      },
      "outputs": [],
      "source": [
        "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70f8f95d",
      "metadata": {
        "id": "70f8f95d"
      },
      "source": [
        "Nous pouvons maintenant exécuter la featurisation sur l'ensemble de notre DataFrame Spark.<br />\n",
        "<u>REMARQUE</u> : Cela peut prendre beaucoup de temps, tout dépend du volume de données à traiter. <br />\n",
        "\n",
        "Notre jeu de données de **Test** contient **22819 images**. <br />\n",
        "Cependant, dans l'exécution en mode **local**, <br />\n",
        "nous <u>traiterons un ensemble réduit de **330 images**</u>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c1767c",
      "metadata": {
        "id": "69c1767c"
      },
      "outputs": [],
      "source": [
        "features_df = images.repartition(20).select(col(\"path\"),\n",
        "                                            col(\"label\"),\n",
        "                                            featurize_udf(\"content\").alias(\"features\")\n",
        "                                           )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb5e83ec",
      "metadata": {
        "id": "eb5e83ec"
      },
      "source": [
        "<u>Rappel du PATH où seront inscrits les fichiers au format \"**parquet**\" <br />\n",
        "contenant nos résultats, à savoir, un DataFrame contenant 3 colonnes</u> :\n",
        " 1. Path des images\n",
        " 2. Label de l'image\n",
        " 3. Vecteur de caractéristiques de l'image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67fcdb0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67fcdb0f",
        "outputId": "8180d44d-8208-4c1c-ebc0-6d16fb0573ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/OC-Projet-8/data/Results\n"
          ]
        }
      ],
      "source": [
        "print(PATH_Result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8901db3",
      "metadata": {
        "id": "f8901db3"
      },
      "source": [
        "<u>Enregistrement des données traitées au format \"**parquet**\"</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d07466",
      "metadata": {
        "id": "95d07466"
      },
      "outputs": [],
      "source": [
        "features_df.write.mode(\"overwrite\").parquet(PATH_Result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9506f21",
      "metadata": {
        "id": "f9506f21"
      },
      "source": [
        "## 3.8 Chargement des données enregistrées et validation du résultat\n",
        "\n",
        "<u>On charge les données fraichement enregistrées dans un **DataFrame Pandas**</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19243bf5",
      "metadata": {
        "id": "19243bf5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(PATH_Result, engine='pyarrow')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27f15070",
      "metadata": {
        "id": "27f15070"
      },
      "source": [
        "<u>On affiche les 5 premières lignes du DataFrame</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a1bcdeb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8a1bcdeb",
        "outputId": "edd548e4-e6a2-48e5-daef-f3fa6e0ff496"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                path         label  \\\n",
              "0  file:/content/drive/MyDrive/OC-Projet-8/data/T...     Raspberry   \n",
              "1  file:/content/drive/MyDrive/OC-Projet-8/data/T...     Raspberry   \n",
              "2  file:/content/drive/MyDrive/OC-Projet-8/data/T...     Raspberry   \n",
              "3  file:/content/drive/MyDrive/OC-Projet-8/data/T...  Potato Sweet   \n",
              "4  file:/content/drive/MyDrive/OC-Projet-8/data/T...  Potato Sweet   \n",
              "\n",
              "                                            features  \n",
              "0  [0.14664589, 0.2415223, 0.046039317, 0.0, 0.18...  \n",
              "1  [0.013116983, 0.83082837, 0.0, 0.0, 0.07333384...  \n",
              "2  [0.0, 1.5598888, 0.011063566, 0.49061102, 0.98...  \n",
              "3  [0.07440685, 0.0, 0.0, 0.0, 0.0, 0.0, 1.174558...  \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61997193, 0.0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-188536a3-504a-4bfc-9917-bd3233803cbc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>file:/content/drive/MyDrive/OC-Projet-8/data/T...</td>\n",
              "      <td>Raspberry</td>\n",
              "      <td>[0.14664589, 0.2415223, 0.046039317, 0.0, 0.18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>file:/content/drive/MyDrive/OC-Projet-8/data/T...</td>\n",
              "      <td>Raspberry</td>\n",
              "      <td>[0.013116983, 0.83082837, 0.0, 0.0, 0.07333384...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>file:/content/drive/MyDrive/OC-Projet-8/data/T...</td>\n",
              "      <td>Raspberry</td>\n",
              "      <td>[0.0, 1.5598888, 0.011063566, 0.49061102, 0.98...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>file:/content/drive/MyDrive/OC-Projet-8/data/T...</td>\n",
              "      <td>Potato Sweet</td>\n",
              "      <td>[0.07440685, 0.0, 0.0, 0.0, 0.0, 0.0, 1.174558...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>file:/content/drive/MyDrive/OC-Projet-8/data/T...</td>\n",
              "      <td>Potato Sweet</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61997193, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-188536a3-504a-4bfc-9917-bd3233803cbc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-188536a3-504a-4bfc-9917-bd3233803cbc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-188536a3-504a-4bfc-9917-bd3233803cbc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d3c3794-a345-45d4-a7ab-5cd369dc44bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d3c3794-a345-45d4-a7ab-5cd369dc44bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d3c3794-a345-45d4-a7ab-5cd369dc44bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2794fca",
      "metadata": {
        "id": "e2794fca"
      },
      "source": [
        "<u>On valide que la dimension du vecteur de caractéristiques des images est bien de dimension 1280</u> :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb933b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bb933b9",
        "outputId": "0f6f98fd-5323-4a24-a058-615f888e6e7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df.loc[0,'features'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efe5348d",
      "metadata": {
        "id": "efe5348d"
      },
      "source": [
        "Nous venons de valider le processus sur un jeu de données allégé en local <br />\n",
        "où nous avons simulé un cluster de machines en répartissant la charge de travail <br />\n",
        "sur différents cœurs de processeur au sein d'une même machine.\n",
        "\n",
        "Nous allons maintenant généraliser le processus en déployant notre solution <br />\n",
        "sur un réel cluster de machines et nous travaillerons désormais sur la totalité <br />\n",
        "des 22819 images de notre dossier \"Test\"."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "432.4px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}